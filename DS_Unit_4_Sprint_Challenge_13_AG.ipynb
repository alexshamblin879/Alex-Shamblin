{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexshamblin879/Alex-Shamblin/blob/main/DS_Unit_4_Sprint_Challenge_13_AG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f95c5acf8c3e89e0b0e482c04e0b8abf",
          "grade": false,
          "grade_id": "cell-e98be1092b48b377",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "F9Nz1u5pDOVW"
      },
      "source": [
        "# Sprint Challenge\n",
        "## *Data Science Sprint 13*\n",
        "\n",
        "After a sprint of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
        "\n",
        "The real dataset is massive (almost 8 gigs uncompressed). The data is sampled for you to something more manageable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge.\n",
        "\n",
        "## Challenge Objectives\n",
        "Successfully complete all these objectives to earn full credit.\n",
        "\n",
        "**Successful completion is defined as passing all the unit tests in each objective.**  \n",
        "\n",
        "There are 8 total possible points in this sprint challenge.\n",
        "\n",
        "\n",
        "There are more details on each objective further down in the notebook.*\n",
        "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
        "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
        "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on Yelp rating\n",
        "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu.\n",
        "\n",
        "3) **Comment out the cell that generates a pyLDAvis visual in objective 4 (see instructions in that section).**\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a0fb09b9e122fc2f2a2baae91a22a818",
          "grade": false,
          "grade_id": "cell-e6c3d2173420a581",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "KipQQF_ODOVZ"
      },
      "source": [
        "### Part 0: Import Necessary Packages\n",
        "For this section, you will need to import:\n",
        "- `spacy`\n",
        "- `Pandas`\n",
        "- `Seaborn`\n",
        "- `Matplotlib`\n",
        "- `NearestNeighbors`\n",
        "- `Pipeline`\n",
        "- `TfidfVectorizer`\n",
        "- `KneighborsClassifier`\n",
        "- `GridSearchCV`\n",
        "- `corpora`\n",
        "- `LdaModel`\n",
        "- `gensim`\n",
        "- `re`\n",
        "\n",
        "> **Note: This assignment is optimized to work with these specific packages. You can use import different packages, but note that this may affect how CodeGrade works, and may cause CodeGrade to fail.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8d3d0719eecd5609256125d84cc4218a",
          "grade": false,
          "grade_id": "cell-b29df5c5bfb8c0d8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "8QHkrtHmDOVa"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6b8ad4a1ac317df7b82aced26eee406f",
          "grade": true,
          "grade_id": "cell-be1ef923d085ceb5",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "WK5ojC0wDOVb"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert pd.__package__ == 'pandas'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "11b700564f5d76c1ec246d8fece821c1",
          "grade": false,
          "grade_id": "cell-c94bee05bece8c59",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Wy35DwIIDOVc"
      },
      "source": [
        "\n",
        "\n",
        "### Part 0: Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "150e28699f961709cb59be5e0f8ddbe0",
          "grade": false,
          "grade_id": "cell-395851cd95d17235",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "fLfIOJijDOVc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Load reviews from URL\n",
        "data_url = 'https://raw.githubusercontent.com/bloominstituteoftechnology/data-science-practice-datasets/main/unit_4/unit1_nlp/review_sample.json'\n",
        "\n",
        "#Import data into a DataFrame named df\n",
        "# Read the data as a string\n",
        "data = pd.read_json(data_url, lines=True)  # lines=True to read data line by line\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "356579363f311da83f4ef7abaf3c9212",
          "grade": true,
          "grade_id": "cell-cb5006475e42b8f9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "p1MKWSY3DOVc"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert isinstance(df, pd.DataFrame), 'df is not a DataFrame. Did you import the data into df?'\n",
        "assert df.shape[0] == 10000, 'DataFrame df has the wrong number of rows.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "aedd47e33e28a74846b51e236deef316",
          "grade": false,
          "grade_id": "cell-27dc6b438d2f2722",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "bniIXd4oDOVd"
      },
      "source": [
        "## Part 1: Tokenize Function\n",
        "<a id=\"#p1\"></a>\n",
        "\n",
        "Complete the function `tokenize`. Your function should\n",
        "- Accept one document at a time\n",
        "- Return a list of tokens\n",
        "\n",
        "You are free to use any method you have learned this week.\n",
        "\n",
        "**TO PASS CODEGRADE RUNTIME:**\n",
        "- Do not run your tokenize function more than one time in your notebook! It is not needed until Part 4!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4G7HD8AMDOVd"
      },
      "outputs": [],
      "source": [
        "# Optional: Consider using spaCy in your function. The spaCy library can be imported by running this cell.\n",
        "# A pre-trained model (en_core_web_sm) has been made available to you in the CodeGrade container.\n",
        "# If you DON'T need use the en_core_web_sm model, you can comment it out below.\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4837ed2a1cc13057ba40203859d46ff6",
          "grade": false,
          "grade_id": "cell-3d570d5a1cd6cb64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "_a_1YPw4DOVd"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE\n",
        "\n",
        "def tokenize(doc):\n",
        "  tokenized_doc = nlp(doc)\n",
        "  tokens = [token.text for token in tokenized_doc]\n",
        "  return tokens\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2181ca9d36070260b1f75dcfd9e58965",
          "grade": true,
          "grade_id": "cell-02da164f6fbe730a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "y7PvjcyiDOVd"
      },
      "outputs": [],
      "source": [
        "'''Testing'''\n",
        "assert isinstance(tokenize(df.sample(n=1)[\"text\"].iloc[0]), list), \"Make sure your tokenizer function accepts a single document and returns a list of tokens!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d4137c3ea2fa84821d1dbf1b28dde6dd",
          "grade": false,
          "grade_id": "cell-ef13337bc7694c52",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "6DxXeXY6DOVe"
      },
      "source": [
        "## Part 2: Vector Representation\n",
        "<a id=\"#p2\"></a>\n",
        "1. Create a vector representation of the reviews (i.e. create a doc-term matrix).\n",
        "    * Name that doc-term matrix `dtm`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fefca7db0abb1474d316d6aa24e032f8",
          "grade": false,
          "grade_id": "cell-0e96491cb529202c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq06xVzlDOVe",
        "outputId": "4995748a-0189-4398-92e7-92a02896d4e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 55s, sys: 732 ms, total: 4min 56s\n",
            "Wall time: 5min 19s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# YOUR CODE HERE\n",
        "dtm = TfidfVectorizer(tokenizer=tokenize)\n",
        "dtm = dtm.fit_transform(df.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "86048b7ea6cb011227aefa5a8f7a9e65",
          "grade": false,
          "grade_id": "cell-33c058ea193687c3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ykmOMZBFDOVe"
      },
      "source": [
        "\n",
        "2. Write a fake review. Assign the text of the review to an object called `fake_review`.\n",
        "3. Query the fake review for the 10 most similar reviews, print the text of the reviews.\n",
        "    - Given the size of the dataset, use `NearestNeighbors` model for this. Name the model `nn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f6aa466983420c836879d744ffa6c9a8",
          "grade": false,
          "grade_id": "cell-3d5bc610a8ec6b24",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "H2USA25GDOVe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "a58b31ea-2163-4eed-f52f-9ea5bf39ab66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(n_neighbors=10)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>NearestNeighbors</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors(n_neighbors=10)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Create and fit a NearestNeighbors model named \"nn\"\n",
        "# YOUR CODE HERE\n",
        "nn = NearestNeighbors(n_neighbors=10)\n",
        "nn.fit(dtm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d270ed23df3c7d3c6cf08ab174ccaf9e",
          "grade": true,
          "grade_id": "cell-c43704dcff67e99b",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ZVYs9V_EDOVe"
      },
      "outputs": [],
      "source": [
        "'''Testing.'''\n",
        "assert nn.__module__ == 'sklearn.neighbors._unsupervised', ' nn is not a NearestNeighbors instance.'\n",
        "assert nn.n_neighbors == 10, 'nn has the wrong value for n_neighbors'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3da2ced9f187ed0aa1a890785e2ba00e",
          "grade": false,
          "grade_id": "cell-496203e8746296ca",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "07NeDoo3DOVe"
      },
      "outputs": [],
      "source": [
        "# Create a fake review and find the 10 most similar reviews\n",
        "\n",
        "# YOUR CODE HERE\n",
        "fake_review = \"This is a fake review. It is not in the dataset.\"\n",
        "similarity, indices = nn.kneighbors(dtm[dtm.shape[0]-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "33e150190aa62764e07f1f6c66bb9393",
          "grade": true,
          "grade_id": "cell-203092260fb65165",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "G49vDGzXDOVe"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert isinstance(fake_review, str), \"Did you write a review in the correct data type?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlVd8m3mDOVf"
      },
      "source": [
        "## Part 3: Classification\n",
        "<a id=\"#p3\"></a>\n",
        "Your goal in this section will be to predict `stars` from the review dataset.\n",
        "\n",
        "1. Create a pipeline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier.\n",
        "    - Use that pipeline to train a model to predict the `stars` feature (i.e. the labels).\n",
        "    - Use that pipeline to predict a star rating for your fake review from Part 2.\n",
        "\n",
        "\n",
        "\n",
        "2. Create a parameter dict including `one parameter for the vectorizer` and `one parameter for the model`.\n",
        "    - Include 2 possible values for each parameter\n",
        "        - **Keep the values for each parameter low. Extreme values will compromise runtime**\n",
        "    - **Use `n_jobs` = 1**\n",
        "    - Due to limited computational resources on CodeGrader `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE.`\n",
        "    \n",
        "    \n",
        "3. Train the entire pipeline with a GridSearch\n",
        "    - Name your GridSearch object as `gs`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "deletable": false,
        "jupyter": {
          "outputs_hidden": true
        },
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b3492e82185541e6a463f46b16baff94",
          "grade": false,
          "grade_id": "cell-e2beb0252d274bba",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "q6muLUyFDOVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58821469-d339-42c3-e05f-5be78e433544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted star rating for fake review: 1\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "def review_to_vector(review):\n",
        "  return dtm[dtm.shape[0]-1]\n",
        "\n",
        "n_jobs = 1\n",
        "\n",
        "# YOUR CODE HERE\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression # Example classifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 1. Create a pipeline object\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),  # Using TfidfVectorizer\n",
        "    ('classifier', LogisticRegression()),  # Example classifier\n",
        "])\n",
        "\n",
        "# 2. Create a parameter dict\n",
        "param_grid = {\n",
        "    'tfidf__max_features': [1000, 2000],  # Parameter for vectorizer\n",
        "    'classifier__C': [0.1, 1.0],  # Parameter for classifier\n",
        "}\n",
        "\n",
        "# 3. Train the pipeline with GridSearchCV\n",
        "gs = GridSearchCV(pipeline, param_grid, n_jobs=1)\n",
        "gs.fit(df['text'], df['stars'])  # Fitting to training data\n",
        "\n",
        "# Predict star rating for the fake review\n",
        "prediction = gs.predict([fake_review])[0]\n",
        "print(f\"Predicted star rating for fake review: {prediction}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ada8e7da1ec21f54451752e97b8cec3e",
          "grade": true,
          "grade_id": "cell-d07134c6fe5d056e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1GHPlRMWDOVf"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "prediction = gs.predict([\"This is your prediction statement.\"])[0]\n",
        "assert prediction in df.stars.values, 'You gs object should be able to accept raw text within a list. Did you include a vectorizer in your pipeline?'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2990aa9aa4e9c3cf665cee4392cdab92",
          "grade": false,
          "grade_id": "cell-00b8cbd0b1b4ece5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "HuJVeCEwDOVf"
      },
      "source": [
        "## Part 4: Topic Modeling\n",
        "\n",
        "Let's find out what those yelp reviews are saying! :D\n",
        "\n",
        "1. Estimate a LDA topic model of the review text\n",
        "    - Set num_topics to `5`\n",
        "    - Name your LDA model `lda`\n",
        "2. Create 1-2 visualizations of the results\n",
        "    - You can use the most important 3 words of a topic in relevant visualizations.\n",
        "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
        "\n",
        "When you instantiate your LDA model, it should look like this:\n",
        "\n",
        "```python\n",
        "lda = LdaModel(corpus=corpus,\n",
        "               id2word=id2word,\n",
        "               random_state=723812,\n",
        "               num_topics = num_topics,\n",
        "               passes=1\n",
        "              )\n",
        "\n",
        "```\n",
        "\n",
        "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9b07079124654b07cce6d10dae1912b6",
          "grade": false,
          "grade_id": "cell-9eee6fe0eeebb9a3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Z_BgokkaDOVf"
      },
      "source": [
        "## Note about  pyLDAvis\n",
        "\n",
        "**pyLDAvis** is the Topic modeling package that we used in class to visualize the topics that LDA generates for us.\n",
        "\n",
        "You are welcomed to use pyLDAvis if you'd like for your visualization. However, **you MUST comment out the code that imports the package and the cell that generates the visualization before you submit your notebook to CodeGrade.**\n",
        "\n",
        "Although you should leave the print out of the visualization for graders to see (i.e. comment out the cell after you run it to create the viz)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "58830f560044227aa07c22d463e1596c",
          "grade": false,
          "grade_id": "cell-ec7b71ad284832d4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ZxEKMJtLDOVf"
      },
      "source": [
        "### 1. Estimate a LDA topic model of the review text\n",
        "\n",
        "* Use the `tokenize` function you created earlier to create tokens.\n",
        "* Create an `id2word` object.\n",
        "> Hint: Use `corpora.Dictionary`\n",
        "* Create a `corpus` object.\n",
        "> Hint: Use `id2word.doc2bow`\n",
        "* Instantiate an `lda` model.\n",
        "\n",
        ">> Remember to read the LDA docs for more information on the various class attributes and methods available to you in the LDA model: https://radimrehurek.com/gensim/models/ldamodel.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bef17fce3f84cc31020898134cfdaec1",
          "grade": false,
          "grade_id": "cell-b4df1a20c7947a8b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "kCNRz9SuDOVf"
      },
      "outputs": [],
      "source": [
        "# Do not change this value\n",
        "num_topics = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fb50f495592df233d97bd4199b958404",
          "grade": false,
          "grade_id": "cell-66331a185ff52f15",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "5ThQdrQKDOVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b7da8df-59f5-4ade-8b75-a2077f9bcb35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "# Assuming you have already defined the 'tokenize' function and 'num_topics' variable\n",
        "\n",
        "# Tokenize the reviews\n",
        "tokenized_reviews = [tokenize(review) for review in df['text']]\n",
        "\n",
        "# Create an id2word object\n",
        "id2word = corpora.Dictionary(tokenized_reviews)\n",
        "\n",
        "# Create a corpus object\n",
        "corpus = [id2word.doc2bow(review) for review in tokenized_reviews]\n",
        "\n",
        "# Instantiate an lda model\n",
        "lda = LdaModel(corpus=corpus,\n",
        "               id2word=id2word,\n",
        "               random_state=723812,\n",
        "               num_topics=num_topics,\n",
        "               passes=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G9fRXicDOVf"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "073be746ce974f75f29c2c92f35af430",
          "grade": true,
          "grade_id": "cell-5a3c181311134fa9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7tvurSbhDOVg"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "\n",
        "assert lda.get_topics().shape[0] == 5, 'Did your model complete its training? Did you set num_topics to 5?'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybQvyG-gDOVg"
      },
      "source": [
        "#### 2. Create 2 visualizations of the results:\n",
        "1. Create a visualization using pyLDAvis. Run the cell, then comment out your code before submission, leaving the visualization in the cell.\n",
        "\n",
        "2. Create a visualization using the matplotlib library and utilizing the subplots function. Assign this visualization to a variable called `visual_plot`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o655HvNWPD3L",
        "outputId": "8769bb40-ed7c-46e5-d7e4-a3acd18367ea"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.4)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.10.2)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.6.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.5.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.17.0)\n",
            "Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-2.0 pyLDAvis-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "DH6PNAsaDOVg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "outputId": "b000f11e-d8a4-4e32-f426-e5224acf7ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el64571370582298795207938405914\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el64571370582298795207938405914_data = {\"mdsDat\": {\"x\": [-0.04312434708537218, -0.03820620406848688, -0.043302351128924596, -0.022117798219258356, 0.14675070050204203], \"y\": [-0.06343840387587288, -0.02603120959631866, 0.0036652870153268935, 0.09571603374216363, -0.009911707285298912], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [36.49798320518223, 32.25290248475793, 22.949364541854813, 8.009422274492449, 0.29032749371256633]}, \"tinfo\": {\"Term\": [\".\", \"I\", \",\", \" \", \"and\", \"a\", \"the\", \"to\", \"my\", \"!\", \"it\", \"was\", \"for\", \"that\", \"me\", \"of\", \"in\", \"not\", \"\\\"\", \"we\", \"with\", \"you\", \"The\", \"but\", \"had\", \"\\n\\n\", \"so\", \"on\", \"-\", \"food\", \"Thai\", \"bento\", \"enchilada\", \"Curry\", \"tamale\", \"gooey\", \"tempura\", \"gyros\", \"shawarma\", \"Meat\", \"\\u00e0\", \"tartar\", \"enchiladas\", \"horribly\", \"Tikka\", \"Margarita\", \"est\", \"Pad\", \"establishments\", \"Asia\", \"dans\", \"frills\", \"Johnny\", \"chipotle\", \"ricotta\", \"cauliflower\", \"Ate\", \"tr\\u00e8s\", \"avec\", \"Noodles\", \"curry\", \"le\", \"spicy\", \"de\", \"rice\", \"soup\", \"et\", \"ramen\", \"salmon\", \"sashimi\", \"en\", \"shrimp\", \"la\", \"broth\", \"fried\", \"delicious\", \"dish\", \"cuisine\", \"sauce\", \"salad\", \"crispy\", \"Mexican\", \"authentic\", \"beef\", \"chicken\", \"fries\", \"tender\", \"roll\", \"fresh\", \"sushi\", \"ordered\", \"tasty\", \"rolls\", \"flavor\", \"food\", \"lunch\", \"cream\", \"The\", \"bread\", \"good\", \".\", \"was\", \"and\", \"taste\", \"place\", \"I\", \"the\", \",\", \"it\", \"\\n\\n\", \"a\", \"but\", \"with\", \"is\", \"It\", \"of\", \"for\", \"were\", \"very\", \"had\", \"-\", \"in\", \"!\", \"are\", \"to\", \"that\", \" \", \"this\", \"so\", \"my\", \"n't\", \"'s\", \"smokey\", \"Depot\", \"painting\", \"pharmacy\", \"humor\", \"increased\", \"Easter\", \"border\", \"Tony\", \"Typical\", \"frustration\", \"UP\", \"tiles\", \"accommodations\", \"pinball\", \"shout\", \"knocking\", \"frittata\", \"floral\", \"inspected\", \"worthwhile\", \"colleague\", \"Adam\", \"fryer\", \"accessories\", \"Girl\", \"vary\", \"Nachos\", \"Beers\", \"urban\", \"heater\", \"p.m.\", \"routine\", \"Waitress\", \"IPA\", \"Bonus\", \"couples\", \"our\", \"windows\", \"promised\", \"we\", \"bikes\", \",\", \"us\", \"to\", \"of\", \".\", \"the\", \"a\", \" \", \"were\", \"they\", \"range\", \"show\", \"We\", \"and\", \"on\", \"have\", \"\\\"\", \"at\", \"for\", \"was\", \"that\", \"not\", \"in\", \"with\", \"'s\", \"from\", \"it\", \"up\", \"is\", \"one\", \"be\", \"n't\", \"\\n\\n\", \"The\", \"I\", \"but\", \"had\", \"you\", \"\\u3002\", \"greatest\", \"TIME\", \"surgery\", \"OVER\", \"PLACE\", \"goals\", \"facials\", \"Motel\", \"Macy\", \"ghetto\", \"YOUR\", \"gyms\", \"Jenn\", \"Step\", \"ANYONE\", \"RECOMMEND\", \"horrific\", \"HERE\", \"yoga\", \"gates\", \"attorney\", \"clowns\", \"boots\", \"Hidden\", \"airline\", \"airlines\", \"authority\", \"CHECK\", \"sweetest\", \"ID\", \"passengers\", \"instructors\", \"tan\", \"ZERO\", \"classes\", \"bath\", \"gym\", \"shower\", \"DO\", \"TO\", \"supplies\", \"!\", \"room\", \"security\", \"emailed\", \"suite\", \"spa\", \"rent\", \"you\", \"?\", \"hotel\", \"desk\", \"LOVE\", \"....\", \"..\", \"...\", \"NOT\", \"class\", \"airport\", \"I\", \"to\", \"stay\", \" \", \"know\", \"in\", \"the\", \"store\", \"if\", \"is\", \"\\\"\", \"have\", \"n't\", \"do\", \"&\", \"a\", \"this\", \"there\", \".\", \"that\", \"it\", \",\", \"your\", \"are\", \"about\", \"and\", \"for\", \"on\", \"so\", \"of\", \"my\", \"was\", \"\\n\\n\", \"'s\", \"they\", \"me\", \"not\", \"but\", \"with\", \"yuk\", \"therapist\", \"implants\", \"removal\", \"Jamie\", \"Suzi\", \"Yuk\", \"brakes\", \"Animal\", \"Howard\", \"servicing\", \"Lewis\", \"cavities\", \"sensor\", \"Acura\", \"Josh\", \"readings\", \"Pest\", \"permanently\", \"tint\", \"Debbie\", \"surgeon\", \"Doctor\", \"acrylics\", \"increase\", \"Ladies\", \"dental\", \"und\", \"Massage\", \"canals\", \"stylist\", \"dentist\", \"consultation\", \"lenses\", \"hair\", \"appointment\", \"pedicure\", \"massages\", \"nails\", \"polish\", \"Dr.\", \"salon\", \"massage\", \"nail\", \"tire\", \"barber\", \"X\", \"manicure\", \"thorough\", \"doctor\", \"car\", \"gel\", \"dealership\", \"procedure\", \"professional\", \"appointments\", \"insurance\", \"my\", \"me\", \"He\", \"job\", \"office\", \"I\", \"She\", \"recommend\", \"him\", \"he\", \"and\", \"patient\", \"i\", \"she\", \"highly\", \"to\", \"did\", \"her\", \".\", \"his\", \"for\", \"was\", \"a\", \"!\", \"with\", \"the\", \"that\", \",\", \"had\", \"in\", \"an\", \"very\", \"is\", \"they\", \"it\", \"of\", \"not\", \"have\", \"this\", \" \", \"at\", \"nite\", \"Filled\", \"gumbo\", \"spiritual\", \"memorabilia\", \"v\", \"Bars\", \"reptiles\", \"halo\", \"Vinyl\", \"Hip\", \"l'entr\\u00e9e\", \"receptive\", \"poss\\u00e8de\", \"n'ai\", \"brandade\", \"d'oignons\", \"Florentine\", \"Mochi\", \"d\\u00e9jeuner\", \"ist\", \"sich\", \"l'ensemble\", \"badass\", \"CO\", \"Aladdin\", \"oder\", \"Swedish\", \"tarte\", \"colorist\", \"_\", \"auch\", \"hier\", \"souvlaki\", \" \", \"Ben\", \"monster\", \",\", \".\", \"j'ai\", \"a\", \"bumper\", \"Free\", \"it\", \"the\", \"that\", \"and\", \"\\\"\", \"I\", \"for\", \"was\", \"not\", \"&\", \"to\", \"we\", \"of\", \"but\", \"-\", \"so\", \"\\n\\n\", \"in\", \"The\", \"on\", \"my\", \"with\", \"had\", \"n't\", \"as\", \"'s\", \"!\", \"is\"], \"Freq\": [65922.0, 33930.0, 36698.0, 14307.0, 38211.0, 27394.0, 45428.0, 27293.0, 9180.0, 15322.0, 13255.0, 20110.0, 12823.0, 9494.0, 4641.0, 15868.0, 12440.0, 6087.0, 3586.0, 5810.0, 9248.0, 8234.0, 9544.0, 7264.0, 6218.0, 8438.0, 5032.0, 7496.0, 5046.0, 4584.0, 204.22015532738635, 26.059713060523656, 26.595685339912272, 28.05991945886957, 23.691742316200553, 16.70369595413071, 50.30552376059252, 22.914813310870716, 33.16132693056194, 29.80364642248486, 51.65538804671674, 16.302360093511815, 47.129403413259325, 17.642035904935753, 16.812678998844227, 13.31705467168206, 30.9611804752281, 38.270948597211266, 12.873634419391541, 21.933552483409624, 12.573456308354437, 13.16407426858909, 18.94488885903509, 14.947723901424125, 15.099843294318473, 28.868044536665465, 16.103584984198527, 22.985794536176883, 16.765473216906738, 25.822988685833447, 113.68663744463169, 43.53815527592015, 317.6223493376931, 135.8953190363722, 446.3384654852942, 421.0458783516233, 64.84756733488182, 150.79737173354752, 177.3823815980775, 79.05185666637317, 39.15911521516027, 258.6806357701691, 99.29648202550281, 132.89046176341972, 403.55073972075763, 1004.4324740704978, 388.8884174888134, 70.28555008728938, 677.7404202324192, 518.4392037549829, 172.58677727047976, 184.36944695157922, 146.97921631440335, 358.4439377300135, 987.7201242193555, 473.2337683599189, 151.53695409304945, 196.6247665607965, 699.4052937388333, 404.1062148008406, 1141.7855578246808, 416.1330435001358, 219.57998866566848, 386.2042939600021, 3027.068876548324, 576.9028858616726, 429.8014919373146, 5367.299459403531, 351.60311272520147, 2679.368047734187, 27797.578946405516, 9442.089298617688, 15641.86074470553, 476.3880192233872, 2646.896552014315, 13546.576229205823, 17131.89414172193, 13217.806735566272, 5567.326097404796, 3848.652901394473, 9779.221694098705, 3371.328663651309, 4071.9775399087175, 5548.925740124906, 1653.7253836141883, 5429.088872671396, 4582.963040563162, 2555.6093883135145, 1921.2762427996208, 2573.0841219661634, 2221.6251894716584, 4151.50403654916, 4645.7857081125985, 2293.348239442623, 6093.764220793659, 3034.597640818731, 3739.09274335474, 2474.8547810610557, 2099.8863986639185, 2664.597534271588, 2388.702944954991, 2247.7171023866294, 19.392609826890585, 23.579890479793615, 24.704715285309494, 12.868541431421761, 12.621316454177233, 12.00409460168616, 11.732206881409523, 14.81001163487353, 44.371376230988304, 11.382692242804717, 15.116156906035464, 11.881202729884752, 9.680562802916244, 9.948628390151656, 9.245380679350573, 23.964563633815914, 9.434810794318425, 8.739046352501257, 9.789618212537631, 9.164085658859106, 8.256608484416978, 14.891818285567558, 12.65779777748607, 12.659856682688511, 16.82566744367224, 11.297695063071416, 10.945096710810018, 11.604152266111765, 9.721084534178745, 13.662908855847617, 19.631831390679, 21.33054428637064, 22.566994262888397, 16.61444389453899, 27.07987606709193, 15.612901069178667, 20.141249431184907, 1748.2406436491926, 50.56349802220564, 30.097881234792673, 3054.3594766832266, 16.266707190238698, 15476.184834748412, 1152.452700225899, 11236.651112156973, 6798.382174831117, 23691.591938651414, 16747.659668130895, 10335.519935579086, 5759.007495808685, 2525.7961937481846, 2904.538449963839, 66.07826207153197, 211.182742560969, 1635.9930702487623, 12299.449927802707, 2981.1381944189498, 2766.7455412449226, 1520.4385669068165, 2126.162954026391, 4195.099315996374, 6017.489377798515, 3184.177827579848, 2177.322580959106, 3919.393815792367, 3007.036633527704, 2132.7330226986196, 1237.9679190847232, 3952.0644368539743, 1184.5013275738975, 4017.1988100899616, 1165.302349267027, 1691.6935088861787, 2309.035644786446, 2558.1115313664977, 2761.0065148265567, 6144.363017456545, 2268.344495038715, 1905.3106018833778, 1901.2958791591257, 33.67814848302902, 30.031044775776618, 21.33876063574496, 28.863638670509324, 14.232526193524306, 21.464554738216055, 21.550932576849164, 25.354683548603234, 8.980269382923728, 10.719067016654167, 8.745522091736818, 18.101124982310285, 15.066240095583263, 9.090442488703049, 10.206196259071428, 7.385441789781715, 8.33513262877812, 9.043084922770833, 27.983723232277203, 26.880728747963133, 10.675601619520059, 17.378392140130952, 7.667038302228327, 9.502581141997506, 7.344817725437963, 12.081262208687768, 7.838695228008451, 7.471737566273757, 6.496870172548622, 9.6586985824743, 17.48196667871484, 10.488924017408985, 28.13571333258518, 27.119028393578766, 17.719762936431582, 60.934010264686535, 23.401122131917184, 95.22698813568158, 66.6217471755651, 58.73345832596853, 35.64979000687572, 27.93933917976525, 8046.953155262443, 599.7097920576739, 44.676704832588044, 21.30406322039462, 48.92580979767409, 66.32378559963088, 55.773722533364094, 3909.6608072108015, 1064.1169534754151, 262.7121566493193, 113.89711438006421, 72.36752460103543, 294.81296283353237, 413.1547390146076, 1175.8820559793885, 145.56250875732476, 101.70840363883106, 78.53587028225242, 9051.943844827976, 7490.941785977359, 182.320302894388, 4274.684631081801, 554.667109903023, 3583.743274788616, 9973.14597330759, 339.8171892369227, 1021.0466530561383, 3604.6654593571698, 1241.096171972895, 2131.650159390962, 2143.079448353175, 1176.2279814998947, 464.20229906547075, 5752.286704650253, 1937.9382125777583, 1227.6798732855984, 10632.012624684947, 2480.5159410769015, 3124.29553060495, 6651.326477019281, 828.8206985084225, 1608.4269179415192, 898.6206011554698, 6231.620619249353, 2813.228474328626, 1902.2813068469727, 1432.6467011258749, 3071.2983591352245, 2137.8589126907414, 3178.904530299834, 1890.6816987371049, 1548.3070786727599, 1615.9130648487105, 1309.370040435635, 1365.417024391225, 1371.4719546859615, 1392.3870896209205, 55.313857552923515, 35.3107301839123, 15.594685797640278, 22.41212316966993, 13.663021159670183, 12.745438630667136, 11.692221563368744, 11.078503148746151, 13.015785844486915, 11.459471588495976, 10.239548825022348, 9.873267911972007, 8.889382767414858, 9.977959691956054, 10.71661242453809, 25.12227669859266, 9.754012391698916, 9.035190088297277, 9.71942754502582, 17.818375648450825, 7.460447034344764, 7.871438676214054, 14.05930067132984, 10.055816730964056, 10.61572496231089, 8.613600484431144, 54.69506082003416, 8.711331777621995, 11.314436202744494, 7.9401209125154155, 73.26222277180979, 57.366067088870466, 22.94205509933852, 12.708053596995162, 381.1972154889485, 318.4492597233308, 116.81138912221958, 31.836714550820727, 179.9207089431562, 76.67310579785807, 187.52956588844137, 179.82678504316095, 125.75913218456844, 172.9443713385462, 68.56655059663875, 38.919373149102476, 20.403042049295447, 51.15121119882236, 50.300661702080966, 79.43543414549131, 408.4163986128326, 84.08578665496721, 58.01060524425361, 43.811049187878496, 225.19255771632731, 57.33327060984135, 74.82334624517524, 2471.022836671684, 1317.6360653476804, 385.2361277150697, 248.98233137102065, 176.784905462333, 5157.203566427723, 320.354998412481, 425.9573235527677, 296.41622590032307, 546.2764105134734, 4004.934188120663, 93.65637987850255, 371.1558094951947, 496.1174804070466, 196.6170322849285, 2451.6608583245334, 651.9669884446658, 386.03928470038585, 3716.7774835950354, 283.5384780495292, 1211.9441096199193, 1449.9249076171172, 1482.3820550342523, 1066.6741601535512, 766.569203787063, 1531.711994469706, 775.2126137306192, 1284.5714080579369, 624.4120412177732, 773.8816130385584, 433.3306018883726, 480.92766689698567, 631.9461773027348, 510.53380876503155, 584.9797002592502, 553.7580919147964, 459.51424787357973, 465.33848921018006, 448.88248065379173, 466.0967693929838, 432.0582067574876, 2.202945352381352, 1.2288261314187294, 2.324477137944141, 0.8449335484356627, 0.7271378228921535, 0.6600972644919729, 0.7133515178388378, 1.0825814016038022, 0.5358884718343419, 0.6130270998690408, 0.6660106258446427, 0.6290992313106873, 0.7419636720002467, 0.5960680952126185, 0.5954924720783725, 0.5171643603906467, 0.5171643603906467, 0.41959356363383055, 0.4420421691240782, 0.4242551801694419, 0.6842286772093391, 0.6842286772093391, 0.514803731422074, 0.5273962608710375, 0.42127921358195675, 0.8375162204510356, 0.5741516638169011, 0.7088659270471935, 0.47226040491521154, 0.5382106961994968, 6.939913615045761, 0.5267373069935265, 0.5267373069935265, 1.171650651009691, 68.72159912702115, 1.0560125507110278, 0.8365114021842541, 68.75324853349059, 84.12540663679839, 1.01487191193277, 45.46604190668024, 1.047499660345883, 1.7391877489586889, 26.481444022022227, 44.440967859228216, 20.335886987858245, 33.793960548657665, 12.549794099439545, 30.73489843913597, 20.23665796505008, 22.12823083267959, 13.159805908413826, 6.463623402273806, 20.734315629625502, 11.559872582572497, 16.318110418254303, 12.17248587144622, 10.435251127559452, 9.865576972288192, 11.211148527447525, 12.406308704149428, 11.30203979380047, 10.408723523991101, 10.796316382152527, 10.493728685669273, 9.296221201769795, 9.24419963028735, 8.314758730787629, 8.704805916231628, 10.046095776157085, 9.635852117006285], \"Total\": [65922.0, 33930.0, 36698.0, 14307.0, 38211.0, 27394.0, 45428.0, 27293.0, 9180.0, 15322.0, 13255.0, 20110.0, 12823.0, 9494.0, 4641.0, 15868.0, 12440.0, 6087.0, 3586.0, 5810.0, 9248.0, 8234.0, 9544.0, 7264.0, 6218.0, 8438.0, 5032.0, 7496.0, 5046.0, 4584.0, 208.77870929667574, 26.81040278938229, 27.414464277510834, 29.074471743533156, 24.602151559563186, 17.43353168100734, 52.54589994607031, 23.94548272446732, 34.65411023732614, 31.174258449246935, 54.09372111087836, 17.08777276023428, 49.40424824340447, 18.53994538565677, 17.723905435626666, 14.046696685872377, 32.67371546652874, 40.38792959826082, 13.587796118050157, 23.168160932163968, 13.285314492724192, 13.926556468033741, 20.06433078762585, 15.856466408456596, 16.02487722078124, 30.709709940671054, 17.130957480170878, 24.472457826560156, 17.85729278373347, 27.515683176561716, 122.34298449156532, 46.43058345130653, 346.1161623350124, 147.17876440303357, 496.834074023038, 471.2406567210038, 69.98333017662122, 166.03942101668034, 196.14537463737437, 86.02224417463604, 42.01308893921302, 290.65731891473513, 108.66690673025987, 146.95245724882955, 466.1702163488331, 1199.068496405037, 452.20017242390685, 77.05092304640323, 817.9773980004765, 617.8320018320521, 196.5497138545634, 211.46398236161636, 166.72915953748875, 426.7460680858351, 1241.6711171371358, 576.8762493154229, 172.6378342801013, 227.82545827483534, 879.3850893093891, 492.78159143437813, 1508.398053295779, 510.24065090323626, 257.3865793329188, 481.3159549186137, 4584.606027474595, 755.5260039456119, 550.2191873833912, 9544.26776743667, 439.56778741508185, 4448.226857467636, 65922.0863999737, 20110.536345165838, 38211.65944042691, 633.944838539231, 4793.662813968078, 33930.8215563572, 45428.85274548934, 36698.64270392539, 13255.147209144992, 8438.724794381124, 27394.87643126898, 7264.950419273651, 9248.464195530074, 13812.372038991776, 3167.9430908359664, 15868.845608970789, 12823.47159847313, 5856.420919465623, 4048.040908534747, 6218.501597653505, 5046.828498851881, 12440.929048872851, 15322.865829911269, 5768.536743817494, 27293.75229288215, 9494.839910193956, 14307.603238765229, 6725.040260700761, 5032.794279684877, 9180.718580787272, 7244.327066352465, 6098.33443502465, 20.17452461436346, 24.592215112644297, 25.813963367138076, 13.637084069240807, 13.414638476946955, 12.826025109318996, 12.536458421151504, 15.83250541415867, 47.44801898804877, 12.228297474462915, 16.268336162673428, 12.806315536997248, 10.477080748956325, 10.792546321568814, 10.040058283362024, 26.030797409267212, 10.259299556814987, 9.506360217115844, 10.649599449771694, 9.97895382966122, 8.996120228869687, 16.259342286693332, 13.834626065829047, 13.86151202689503, 18.431881235932686, 12.401431033541352, 12.01706409232922, 12.743969993326504, 10.689800907422537, 15.044492845983312, 21.76406317042473, 23.698589960935102, 25.60730751448553, 18.58700684881264, 31.4065280614368, 17.521088642883797, 23.14966364178165, 2975.186803763775, 63.63568590221966, 36.20070156912066, 5810.93075752608, 18.467781842445596, 36698.64270392539, 2070.8885172011096, 27293.75229288215, 15868.845608970789, 65922.0863999737, 45428.85274548934, 27394.87643126898, 14307.603238765229, 5856.420919465623, 6885.192206726772, 89.85882293003759, 342.23724524415354, 3601.0996378784935, 38211.65944042691, 7496.235041350062, 7182.781748809675, 3586.109787956114, 5375.31741663196, 12823.47159847313, 20110.536345165838, 9494.839910193956, 6087.142533240249, 12440.929048872851, 9248.464195530074, 6098.33443502465, 3150.0890551079187, 13255.147209144992, 3007.834629311386, 13812.372038991776, 2978.4713490035833, 4815.438923045278, 7244.327066352465, 8438.724794381124, 9544.26776743667, 33930.8215563572, 7264.950419273651, 6218.501597653505, 8234.624740456271, 34.37518019911244, 31.236707122448856, 22.296504820343564, 30.440356577575713, 15.089713984955853, 22.97298156397945, 23.129372682121883, 27.434021487909746, 9.756077184527761, 11.658482429627037, 9.525041630938443, 19.717449471633696, 16.472664324162007, 9.96652782319562, 11.206788636556283, 8.135418528083294, 9.186835808701014, 9.974308842291839, 30.8732902463398, 29.7158814595893, 11.821172895429507, 19.25587057711149, 8.497861705727153, 10.539889781277159, 8.163146769423498, 13.429783621485644, 8.717463926480775, 8.310973045550897, 7.23494630258173, 10.760675322500585, 19.586080347505053, 11.693911378592482, 32.31598065815623, 31.126683639558436, 20.100620896709785, 72.63406782416082, 26.849078243454464, 116.72764641498749, 80.37946345646344, 70.68696717383055, 42.555251251761824, 32.850103378716234, 15322.865829911269, 929.7558230102089, 55.3077920353785, 24.88780361515678, 61.61428192073342, 86.6017552244462, 71.61766556923004, 8234.624740456271, 1921.3419045149672, 411.32546087949925, 160.19832188490741, 96.82094976195177, 481.8889536446285, 714.1675990339621, 2401.3298621576855, 218.59045949458803, 146.40157242664338, 108.2703269190247, 33930.8215563572, 27293.75229288215, 304.78681776849936, 14307.603238765229, 1225.081177639068, 12440.929048872851, 45428.85274548934, 688.4896206536761, 2785.0473504064216, 13812.372038991776, 3586.109787956114, 7182.781748809675, 7244.327066352465, 3413.63727289482, 1037.8084714296026, 27394.87643126898, 6725.040260700761, 3716.6989161961787, 65922.0863999737, 9494.839910193956, 13255.147209144992, 36698.64270392539, 2304.5839604142075, 5768.536743817494, 2576.231254226809, 38211.65944042691, 12823.47159847313, 7496.235041350062, 5032.794279684877, 15868.845608970789, 9180.718580787272, 20110.536345165838, 8438.724794381124, 6098.33443502465, 6885.192206726772, 4641.632703509619, 6087.142533240249, 7264.950419273651, 9248.464195530074, 56.04058595553162, 36.659238778539105, 16.345758042734104, 23.51738215219463, 14.372128011638043, 13.463782955455562, 12.36155707794881, 11.777810415243383, 13.897518843445155, 12.289528507508043, 10.984124859045268, 10.62190989315683, 9.575414262188016, 10.783764955152401, 11.615380091696496, 27.230778161624475, 10.59538774137541, 9.815689537489854, 10.560454502208463, 19.41584193031407, 8.134994108948908, 8.5908448643266, 15.353879973829736, 10.989677059961052, 11.618388116899608, 9.445371713736817, 59.986581371093955, 9.559717651644373, 12.416826082142396, 8.718897541464179, 80.65208914685694, 63.59885048834167, 25.3193971719503, 14.00293807615829, 454.6717784103764, 378.74350296673697, 136.34723298629717, 35.7671136998666, 219.20476279418452, 90.81197106162062, 231.39240787057327, 225.05019644251297, 155.97620702094378, 221.386213588608, 84.08491478312938, 45.83308073048416, 23.125451153600636, 63.14358117367516, 63.059013782608126, 106.1534643837682, 672.8885229278851, 116.31497123512295, 76.12169686431925, 55.660359910735544, 379.01122300498565, 77.36172209056504, 113.5612206451179, 9180.718580787272, 4641.632703509619, 965.4665118882557, 543.7247037868445, 346.52961413666526, 33930.8215563572, 822.7049364801995, 1223.7560561589933, 744.3421403477097, 2008.5670342074307, 38211.65944042691, 152.78417143173135, 1175.2075603705214, 1829.7920123587162, 461.5432312082493, 27293.75229288215, 3261.7343346931743, 1414.7453254987206, 65922.0863999737, 928.6920754508001, 12823.47159847313, 20110.536345165838, 27394.87643126898, 15322.865829911269, 9248.464195530074, 45428.85274548934, 9494.839910193956, 36698.64270392539, 6218.501597653505, 12440.929048872851, 2739.0896321824266, 4048.040908534747, 13812.372038991776, 6885.192206726772, 13255.147209144992, 15868.845608970789, 6087.142533240249, 7182.781748809675, 6725.040260700761, 14307.603238765229, 5375.31741663196, 3.072578595045772, 2.1474478232737866, 4.328686728837998, 1.7618584307772944, 1.621926145031741, 1.5314850045450106, 1.7445188940835004, 2.6624765543078555, 1.3898882714270704, 1.5976514032591598, 1.7908166495083644, 1.7109062920377318, 2.0535992428620555, 1.7505949386213313, 1.7663826843577786, 1.547804645642978, 1.547804645642978, 1.272357053425689, 1.3407671627306277, 1.2903171025245646, 2.1043251297971795, 2.1043251297971795, 1.6203926182255741, 1.6620632116711525, 1.348971844684897, 2.7106617268697306, 1.8821629444344166, 2.338085136819337, 1.572759173877355, 1.7934505399193594, 33.31929155340222, 1.8042199436248443, 1.8042199436248443, 6.525422679636516, 14307.603238765229, 6.845905103306722, 4.400731004385941, 36698.64270392539, 65922.0863999737, 6.775333153311221, 27394.87643126898, 7.4202799411824785, 23.308081297359426, 13255.147209144992, 45428.85274548934, 9494.839910193956, 38211.65944042691, 3586.109787956114, 33930.8215563572, 12823.47159847313, 20110.536345165838, 6087.142533240249, 1037.8084714296026, 27293.75229288215, 5810.93075752608, 15868.845608970789, 7264.950419273651, 5046.828498851881, 5032.794279684877, 8438.724794381124, 12440.929048872851, 9544.26776743667, 7496.235041350062, 9180.718580787272, 9248.464195530074, 6218.501597653505, 7244.327066352465, 4325.734980389052, 6098.33443502465, 15322.865829911269, 13812.372038991776], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.7655, -9.8243, -9.804, -9.7504, -9.9196, -10.2691, -9.1666, -9.9529, -9.5833, -9.6901, -9.1401, -10.2934, -9.2318, -10.2144, -10.2626, -10.4957, -9.652, -9.44, -10.5295, -9.9967, -10.5531, -10.5072, -10.1432, -10.3802, -10.37, -9.722, -10.3057, -9.9499, -10.2654, -9.8335, -8.3513, -9.3111, -7.3239, -8.1728, -6.9836, -7.042, -8.9127, -8.0688, -7.9064, -8.7146, -9.4171, -7.5291, -8.4866, -8.1952, -7.0844, -6.1725, -7.1214, -8.8322, -6.566, -6.8339, -7.9338, -7.8678, -8.0944, -7.203, -6.1893, -6.9251, -8.0639, -7.8034, -6.5345, -7.083, -6.0444, -7.0537, -7.693, -7.1284, -5.0694, -6.7271, -7.0214, -4.4966, -7.2222, -5.1914, -2.852, -3.9318, -3.427, -6.9185, -5.2036, -3.5708, -3.336, -3.5954, -4.4601, -4.8292, -3.8967, -4.9617, -4.7728, -4.4634, -5.6739, -4.4852, -4.6546, -5.2387, -5.524, -5.2319, -5.3787, -4.7535, -4.641, -5.347, -4.3697, -5.0669, -4.8581, -5.2708, -5.4351, -5.1969, -5.3062, -5.3671, -9.9962, -9.8007, -9.7541, -10.4063, -10.4257, -10.4758, -10.4987, -10.2658, -9.1685, -10.529, -10.2453, -10.4861, -10.691, -10.6636, -10.737, -9.7845, -10.7167, -10.7933, -10.6798, -10.7458, -10.8501, -10.2603, -10.4228, -10.4226, -10.1382, -10.5365, -10.5682, -10.5097, -10.6868, -10.3464, -9.9839, -9.9009, -9.8446, -10.1508, -9.6623, -10.213, -9.9583, -5.4947, -9.0378, -9.5566, -4.9368, -10.172, -3.314, -5.9114, -3.6341, -4.1366, -2.8882, -3.2351, -3.7177, -4.3026, -5.1268, -4.987, -8.7702, -7.6084, -5.5611, -3.5438, -4.961, -5.0357, -5.6343, -5.299, -4.6194, -4.2587, -4.8951, -5.2752, -4.6874, -4.9524, -5.2959, -5.8399, -4.6791, -5.884, -4.6627, -5.9003, -5.5276, -5.2165, -5.1141, -5.0377, -4.2378, -5.2343, -5.4087, -5.4108, -9.1039, -9.2185, -9.5602, -9.2582, -9.9652, -9.5544, -9.5503, -9.3878, -10.4257, -10.2487, -10.4522, -9.7248, -9.9083, -10.4135, -10.2978, -10.6212, -10.5003, -10.4188, -9.2891, -9.3294, -10.2528, -9.7655, -10.5838, -10.3692, -10.6268, -10.1291, -10.5617, -10.6096, -10.7494, -10.3529, -9.7596, -10.2704, -9.2837, -9.3205, -9.7461, -8.511, -9.468, -8.0645, -8.4217, -8.5478, -9.047, -9.2907, -3.6277, -6.2243, -8.8213, -9.5619, -8.7305, -8.4262, -8.5995, -4.3496, -5.6509, -7.0497, -7.8855, -8.339, -6.9344, -6.5969, -5.551, -7.6402, -7.9987, -8.2572, -3.51, -3.6993, -7.415, -4.2603, -6.3024, -4.4366, -3.4131, -6.7924, -5.6922, -4.4308, -5.497, -4.9561, -4.9508, -5.5507, -6.4804, -3.9634, -5.0514, -5.5079, -3.3491, -4.8045, -4.5738, -3.8182, -5.9008, -5.2377, -5.8199, -3.8834, -4.6787, -5.07, -5.3535, -4.5909, -4.9532, -4.5565, -5.0761, -5.2758, -5.2331, -5.4435, -5.4015, -5.3971, -5.382, -7.5551, -8.0039, -8.8212, -8.4585, -8.9534, -9.0229, -9.1092, -9.1631, -9.0019, -9.1293, -9.2418, -9.2783, -9.3832, -9.2677, -9.1963, -8.3443, -9.2904, -9.367, -9.294, -8.6879, -9.5585, -9.5048, -8.9248, -9.2599, -9.2058, -9.4147, -7.5663, -9.4035, -9.142, -9.4962, -7.274, -7.5186, -8.4351, -9.0259, -5.6248, -5.8046, -6.8075, -8.1075, -6.3756, -7.2285, -6.3342, -6.3761, -6.7337, -6.4151, -7.3403, -7.9066, -8.5524, -7.6333, -7.6501, -7.1931, -5.5558, -7.1363, -7.5075, -7.7882, -6.1511, -7.5192, -7.253, -3.7557, -4.3845, -5.6142, -6.0507, -6.3932, -3.0199, -5.7987, -5.5137, -5.8763, -5.265, -3.2728, -7.0285, -5.6515, -5.3613, -6.2868, -3.7636, -5.0881, -5.6121, -3.3475, -5.9207, -4.4681, -4.2888, -4.2667, -4.5958, -4.9262, -4.2339, -4.915, -4.4099, -5.1313, -4.9167, -5.4966, -5.3924, -5.1193, -5.3326, -5.1965, -5.2514, -5.4379, -5.4253, -5.4613, -5.4237, -5.4995, -7.4609, -8.0447, -7.4072, -8.4192, -8.5694, -8.6661, -8.5885, -8.1714, -8.8746, -8.7401, -8.6572, -8.7142, -8.5492, -8.7681, -8.7691, -8.9101, -8.9101, -9.1192, -9.0671, -9.1081, -8.6302, -8.6302, -8.9147, -8.8905, -9.1152, -8.428, -8.8056, -8.5948, -9.0009, -8.8702, -6.3134, -8.8918, -8.8918, -8.0923, -4.0207, -8.1962, -8.4292, -4.0202, -3.8184, -8.236, -4.4338, -8.2043, -7.6973, -4.9743, -4.4566, -5.2383, -4.7304, -5.721, -4.8253, -5.2432, -5.1539, -5.6736, -6.3845, -5.2189, -5.8032, -5.4584, -5.7515, -5.9055, -5.9617, -5.8338, -5.7325, -5.8257, -5.9081, -5.8715, -5.8999, -6.0211, -6.0267, -6.1327, -6.0868, -5.9435, -5.9852], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9858, 0.9795, 0.9776, 0.9724, 0.9702, 0.9651, 0.9643, 0.9639, 0.9639, 0.963, 0.9618, 0.9609, 0.9608, 0.9583, 0.9551, 0.9546, 0.9541, 0.9541, 0.9539, 0.9532, 0.9528, 0.9516, 0.9505, 0.9489, 0.9485, 0.9461, 0.9461, 0.9452, 0.9448, 0.9444, 0.9345, 0.9436, 0.922, 0.9282, 0.9007, 0.8953, 0.9317, 0.9116, 0.9074, 0.9234, 0.9376, 0.8914, 0.9177, 0.9073, 0.8637, 0.8308, 0.8571, 0.916, 0.8198, 0.8325, 0.8779, 0.8708, 0.8818, 0.8335, 0.7791, 0.8099, 0.8775, 0.8606, 0.7789, 0.8095, 0.7295, 0.804, 0.8491, 0.7878, 0.5928, 0.7382, 0.7609, 0.4323, 0.7846, 0.501, 0.1444, 0.2518, 0.1147, 0.7222, 0.414, 0.0897, 0.0327, -0.0133, 0.1404, 0.2228, -0.0222, 0.2402, 0.1876, 0.096, 0.3579, -0.0647, -0.021, 0.1787, 0.2627, 0.1255, 0.1874, -0.0896, -0.1855, 0.0855, -0.4915, -0.1328, -0.334, 0.0083, 0.1338, -0.2291, -0.1016, 0.0098, 1.092, 1.0895, 1.0876, 1.0736, 1.0706, 1.0653, 1.0653, 1.0648, 1.0645, 1.0599, 1.0581, 1.0566, 1.0525, 1.0501, 1.0491, 1.0489, 1.0478, 1.0474, 1.0474, 1.0464, 1.0458, 1.0437, 1.0427, 1.0409, 1.0404, 1.0383, 1.0381, 1.0379, 1.0366, 1.0352, 1.0285, 1.0263, 1.0052, 1.0194, 0.9833, 1.0163, 0.9924, 0.5999, 0.9016, 0.9469, 0.4884, 1.0047, 0.2681, 0.5455, 0.2441, 0.2839, 0.1082, 0.1337, 0.1568, 0.2215, 0.2906, 0.2685, 0.8242, 0.6488, 0.3426, -0.002, 0.2095, 0.1775, 0.2735, 0.2041, 0.0142, -0.075, 0.039, 0.1035, -0.0235, 0.0081, 0.081, 0.1976, -0.0786, 0.1997, -0.1034, 0.1931, 0.0855, -0.0118, -0.062, -0.1088, -0.5772, -0.0324, -0.0513, -0.3342, 1.4514, 1.4325, 1.428, 1.4187, 1.4134, 1.404, 1.4012, 1.3931, 1.389, 1.3879, 1.3865, 1.3864, 1.3826, 1.3799, 1.3784, 1.3752, 1.3746, 1.3739, 1.3736, 1.3716, 1.3699, 1.3693, 1.369, 1.3683, 1.3662, 1.3661, 1.3656, 1.3654, 1.3643, 1.3638, 1.3582, 1.3631, 1.3334, 1.3341, 1.3458, 1.2962, 1.3344, 1.2683, 1.2842, 1.2866, 1.2948, 1.31, 0.8278, 1.0334, 1.2584, 1.3164, 1.2413, 1.2051, 1.2218, 0.727, 0.881, 1.0236, 1.1308, 1.1808, 0.9805, 0.9246, 0.7579, 1.0653, 1.1076, 1.1508, 0.1505, 0.1789, 0.958, 0.2638, 0.6795, 0.2273, -0.0444, 0.7658, 0.4684, 0.1285, 0.4108, 0.2571, 0.2539, 0.4064, 0.6673, -0.0889, 0.2277, 0.3642, -0.3527, 0.1296, 0.0267, -0.236, 0.4492, 0.1947, 0.4187, -0.3416, -0.0451, 0.1005, 0.2154, -0.1704, 0.0146, -0.3728, -0.024, 0.101, 0.0224, 0.2064, -0.0228, -0.1953, -0.4216, 2.5115, 2.4871, 2.4775, 2.4764, 2.474, 2.4697, 2.4689, 2.4633, 2.459, 2.4546, 2.4544, 2.4515, 2.4502, 2.4469, 2.444, 2.444, 2.4418, 2.4417, 2.4416, 2.4387, 2.438, 2.4371, 2.4365, 2.4357, 2.4343, 2.4324, 2.4322, 2.4316, 2.4316, 2.431, 2.4285, 2.4214, 2.426, 2.4275, 2.3483, 2.3512, 2.3699, 2.4081, 2.3271, 2.3553, 2.3144, 2.3002, 2.3092, 2.2776, 2.3205, 2.361, 2.3993, 2.3139, 2.2985, 2.2346, 2.0253, 2.2001, 2.2528, 2.2852, 2.0039, 2.2249, 2.1073, 1.2121, 1.2653, 1.6058, 1.7435, 1.8515, 0.6406, 1.5814, 1.4692, 1.6038, 1.2225, 0.2689, 2.0352, 1.372, 1.2194, 1.6712, 0.1147, 0.9145, 1.2258, -0.3511, 1.3381, 0.1655, -0.1052, -0.3922, -0.1402, 0.0343, -0.8652, 0.0192, -0.8278, 0.2261, -0.2528, 0.6807, 0.3943, -0.56, -0.0771, -0.596, -0.8308, -0.0592, -0.2121, -0.1823, -0.8996, 0.0035, 5.5092, 5.2837, 5.2201, 5.107, 5.0397, 5.0003, 4.9477, 4.942, 4.8889, 4.884, 4.8528, 4.8414, 4.8239, 4.7646, 4.7546, 4.7457, 4.7457, 4.7326, 4.7323, 4.7296, 4.7185, 4.7185, 4.6953, 4.6941, 4.6781, 4.6674, 4.6546, 4.6485, 4.6389, 4.6383, 4.2731, 4.6107, 4.6107, 4.1246, 0.5034, 3.9728, 4.1816, -0.4381, -0.822, 3.9434, -0.5592, 3.8841, 3.2465, -0.3738, -1.0878, -0.3042, -1.1887, 0.1868, -1.1648, -0.6096, -0.9702, -0.2949, 0.7632, -1.3407, -0.378, -1.0379, -0.5497, -0.3394, -0.3928, -0.7818, -1.0686, -0.8968, -0.7376, -0.9037, -0.9395, -0.6638, -0.8221, -0.4124, -0.71, -1.488, -1.4259]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 2, 1, 2, 5, 4, 1, 2, 1, 5, 2, 2, 3, 4, 5, 1, 2, 3, 3, 1, 1, 2, 3, 4, 4, 2, 3, 4, 1, 2, 3, 4, 2, 5, 2, 3, 5, 1, 2, 1, 2, 3, 1, 2, 3, 4, 5, 3, 5, 4, 1, 2, 3, 4, 5, 2, 3, 1, 2, 1, 2, 3, 4, 5, 4, 3, 1, 2, 2, 4, 1, 2, 3, 4, 4, 4, 3, 1, 3, 4, 1, 2, 1, 2, 3, 4, 3, 1, 2, 3, 4, 2, 3, 1, 2, 3, 2, 3, 1, 2, 4, 3, 1, 2, 3, 4, 5, 3, 4, 4, 5, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 2, 2, 5, 1, 2, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 2, 4, 2, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 3, 1, 2, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 2, 3, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 3, 2, 3, 1, 5, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 1, 1, 2, 3, 1, 3, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 1, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 1, 2, 3, 4, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 4, 2, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 2, 1, 2, 3, 4, 5, 5, 5, 1, 2, 3, 1, 2, 3, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 5, 1, 3, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 4, 2, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 1, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 4, 4, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 4, 2, 3, 1, 2, 3, 4, 3, 1, 1, 2, 3, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3], \"Freq\": [0.45611156825055305, 0.30312636829953615, 0.22408599001345694, 0.015405171180195349, 0.0013035144844780679, 0.26132958383060967, 0.4025132584328647, 0.29879218263596047, 0.032570095230025166, 0.004822610667106731, 0.30320698827308756, 0.10135179784505058, 0.5251628572177218, 0.06963449343249772, 0.0006526194323570546, 0.16703336914327913, 0.42385763121499875, 0.34605744759066676, 0.05939583911104917, 0.0036250981617072264, 0.3382126949845478, 0.15513459798436524, 0.44709598425307745, 0.052996291236894956, 0.00578141358947945, 0.36862524086724896, 0.349767632904734, 0.25383980109541876, 0.026400651147520944, 0.0014758127970663881, 0.3601768083533554, 0.4217049694414078, 0.1812328606716725, 0.03501491895400679, 0.001880178527491415, 0.44027650246198974, 0.29602749535473116, 0.2300454632575923, 0.03170307848511177, 0.001981442405319486, 0.4216796148007095, 0.3593939648125192, 0.1612813031355185, 0.05638474452170074, 0.001274231514614706, 0.2716449195712873, 0.11341875507873336, 0.578295627747122, 0.03360555706036544, 0.0028004630883637868, 0.25985601138500497, 0.21779598390121413, 0.48972863684097095, 0.029983385929039038, 0.0029150514097676843, 0.2137421894006682, 0.1390361814548036, 0.6121742317786129, 0.03527783708554718, 0.0020751668873851283, 0.2191176900949752, 0.20298313334213855, 0.5537796253231677, 0.022900661197574605, 0.0015614087180164504, 0.8604351424374969, 0.9470202363729437, 0.9396712233595862, 0.3689136088385322, 0.3689136088385322, 0.3689136088385322, 0.9354187712529366, 0.949579039286531, 0.04316268360393322, 0.9339816538871243, 0.5732239435132971, 0.9354711174327326, 0.5842908920937149, 0.14607272302342872, 0.14607272302342872, 0.14607272302342872, 0.05707407915010753, 0.9131852664017205, 0.05707407915010753, 0.8293081591855008, 0.9630441525125166, 0.014146879403396104, 0.07073439701698052, 0.8346658848003702, 0.07073439701698052, 0.8604800330832009, 0.9759185941595068, 0.06513011705865047, 0.9118216388211067, 0.021608314836313446, 0.025929977803576133, 0.14693654088693142, 0.8124726378453855, 0.9572081362112291, 0.46566905568653066, 0.12871072319195448, 0.7722643391517268, 0.08580714879463631, 0.08063585543437402, 0.8869944097781142, 0.03239045764221893, 0.06478091528443786, 0.90693281398213, 0.10357687063057255, 0.3128021493043291, 0.18125952360350198, 0.39877095192770434, 0.0031073061189171767, 0.8575124517201786, 0.5584044576950585, 0.8950709535585331, 0.39925352168379385, 0.1810743070218668, 0.26677809686880505, 0.15198570984892043, 0.000913623619413716, 0.05105666791198391, 0.8679633545037265, 0.12736205645448243, 0.8596938810677563, 0.5221053385664001, 0.25979002033866216, 0.1998141954731144, 0.016730098515126482, 0.0018939734168067716, 0.9741076609297727, 0.903022613256929, 0.9469540848936637, 0.04983968867861388, 0.03672315179774298, 0.9180787949435744, 0.15492514829569073, 0.08262674575770172, 0.7436407118193156, 0.02065668643942543, 0.9528476245049103, 0.9414502759473137, 0.9435190271459626, 0.9254844958014148, 0.08053587876520053, 0.8858946664172059, 0.9623324336276137, 0.032077747787587124, 0.8701245382078766, 0.08039194103007556, 0.04256043936886353, 0.004728937707651503, 0.922501926724521, 0.10521959674351407, 0.16469154272897854, 0.6679157010675241, 0.06404671106126944, 0.9416218028042996, 0.07846848356702496, 0.9449156625755599, 0.036342910099059995, 0.927784318109523, 0.04352939548638966, 0.914117305214183, 0.940875166862635, 0.024759872812174604, 0.9168994155352586, 0.870811252817108, 0.16166184752581825, 0.19934242852807663, 0.2479625330471197, 0.38896083615234467, 0.001215502612976077, 0.8923162847365778, 0.9655532953115799, 0.4277004221327761, 0.4277004221327761, 0.9418516565358432, 0.04699772510254415, 0.11749431275636037, 0.8459590518457947, 0.023498862551272075, 0.9771111273138241, 0.014369281284026824, 0.004789760428008941, 0.004789760428008941, 0.5623270564884235, 0.2892835854228689, 0.1300256897898516, 0.017183088739351864, 0.001152524244712625, 0.9591565505550741, 0.02107569549430252, 0.9273306017493109, 0.04215139098860504, 0.02107569549430252, 0.8995528627735756, 0.9370376643720971, 0.625918769238415, 0.05380102391600944, 0.9146174065721605, 0.4137625030774766, 0.45430567451996756, 0.1110771820342219, 0.018883120945817723, 0.0019438506855988832, 0.04324239961235523, 0.04324239961235523, 0.8648479922471046, 0.050716498674873725, 0.050716498674873725, 0.9128969761477271, 0.9707514938717733, 0.04974970699356293, 0.8954947258841328, 0.04974970699356293, 0.0300126429278143, 0.0900379287834429, 0.6302655014841003, 0.0300126429278143, 0.2100885004947001, 0.35696455957866935, 0.37729682869466474, 0.20996626921939934, 0.054097707055485014, 0.0016426429267859823, 0.2763727048306806, 0.28957027781416816, 0.3489593562398622, 0.0838434048362739, 0.0011644917338371375, 0.9223149705879585, 0.05425382179929168, 0.9265654000497624, 0.9099448460076442, 0.07446136350254741, 0.8935363620305689, 0.9176980905763938, 0.12930597328361806, 0.1200698323347882, 0.729655134957559, 0.027708422846489583, 0.2752739418020559, 0.3468305632784524, 0.2179556276602485, 0.1580817198942841, 0.00146033921380401, 0.4093514971362689, 0.32186511080929364, 0.16309158228827694, 0.10481094144167989, 0.0008897807762839242, 0.021122474543682396, 0.04488525840532509, 0.08977051681065018, 0.8396183631113753, 0.038778867881043164, 0.11633660364312949, 0.10341031434944843, 0.7367984897398201, 0.39750115182286966, 0.283607450668214, 0.2787535334196138, 0.039351400551151945, 0.0006934167498000343, 0.39299679885777555, 0.3435254371192085, 0.194880177315944, 0.06704063039338524, 0.001849396700507179, 0.3006334091080607, 0.39551152708152043, 0.222498488424035, 0.08036734698928355, 0.0009301776271907818, 0.05193221443795177, 0.88284764544518, 0.5542561501625505, 0.5542561501625505, 0.8816694116840871, 0.08396851539848448, 0.023991004399566994, 0.011995502199783497, 0.8422599810677164, 0.9519920071807081, 0.055999529834159296, 0.60166183390494, 0.02181830206615126, 0.04363660413230252, 0.08727320826460504, 0.8509137805798991, 0.07449045296322528, 0.03724522648161264, 0.8566402090770907, 0.32914964249980516, 0.35136983918591186, 0.24317617120963522, 0.07559020181068081, 0.0008306615583591298, 0.8389063819751291, 0.13122557930337214, 0.0257764530774481, 0.0023433139161316455, 0.0023433139161316455, 0.9697728230437763, 0.10829670921297552, 0.8663736737038041, 0.09487765249465693, 0.9487765249465694, 0.9474179611892519, 0.9339596760500827, 0.6460763655251772, 0.800786613755225, 0.15697237599179126, 0.038674353505223934, 0.0022749619708955257, 0.0022749619708955257, 0.905054617595102, 0.06804921936805278, 0.027219687747221114, 0.673829025270334, 0.13476580505406677, 0.13476580505406677, 0.46400867252402145, 0.3121838235789026, 0.18871429547031546, 0.033310619623498426, 0.001651766262322236, 0.9175471969884563, 0.03715325666608123, 0.15604367799754118, 0.1991414557301954, 0.6063411487904456, 0.0014861302666432492, 0.9443267310575681, 0.03256299072612304, 0.9399071156158489, 0.7957018459751133, 0.15946251569136885, 0.04026831204327496, 0.003221464963461997, 0.0016107324817309985, 0.9459863007056967, 0.0751358050167918, 0.12978002684718584, 0.6967138283375239, 0.10245791593198882, 0.027535288328361045, 0.06883822082090262, 0.8398262940150119, 0.05507057665672209, 0.9414132963129279, 0.9225465418903211, 0.06150310279268807, 0.5575843758952862, 0.5575843758952862, 0.0394954110956415, 0.0394954110956415, 0.0394954110956415, 0.9083944551997546, 0.08639434382062908, 0.8639434382062907, 0.7815067337889422, 0.14539660163515206, 0.06542847073581842, 0.005452372561318202, 0.003634915040878801, 0.8801844409094944, 0.10175542669473923, 0.015263314004210885, 0.005087771334736962, 0.9084900898311514, 0.051913719418922935, 0.012978429854730734, 0.012978429854730734, 0.9318065966247496, 0.04904245245393419, 0.016347484151311396, 0.008173742075655698, 0.6460763655251772, 0.9785240693488704, 0.9240463497001395, 0.05435566762941997, 0.013588916907354993, 0.006794458453677496, 0.013136859019083862, 0.15764230822900635, 0.0656842950954193, 0.761937823106864, 0.837316636213963, 0.09006991704293626, 0.06505049564212063, 0.005837864993523647, 0.0016679614267210419, 0.016670394897380755, 0.03334078979476151, 0.05001118469214226, 0.9168717193559414, 0.015723554629077933, 0.06289421851631173, 0.031447109258155866, 0.8962426138574422, 0.037453575851503794, 0.16854109133176706, 0.711617941178572, 0.08739167698684218, 0.262743654774268, 0.34092292194747487, 0.1946817045293584, 0.19989365567423886, 0.0018395121687813393, 0.8602385043660244, 0.10393627173574074, 0.03095974051702916, 0.0022114100369306543, 0.0022114100369306543, 0.24050592794933326, 0.34098526203778795, 0.34450057401755896, 0.07235683825028662, 0.0014647133249045875, 0.03768129493672592, 0.11304388481017777, 0.10362356107599628, 0.7442055750003369, 0.12054097044437409, 0.8437867931106185, 0.9282821374174003, 0.04760421217525129, 0.023802106087625646, 0.9848815474446153, 0.9513351922377355, 0.020241174302930546, 0.020241174302930546, 0.9487748655874992, 0.0306056408254032, 0.956740878878119, 0.9287926115541446, 0.057156468403331974, 0.014289117100832993, 0.03645109049873359, 0.9112772624683396, 0.8019680130181207, 0.147512251099188, 0.045708021467354025, 0.002077637339425183, 0.002077637339425183, 0.93900245236119, 0.6602530254202467, 0.24974883188179137, 0.08354043896133283, 0.004798667512139223, 0.00152684875386248, 0.35739151951221154, 0.3271345023682582, 0.21936337429366157, 0.09451418757337997, 0.0015596400589666661, 0.7948736094092161, 0.15351636233225205, 0.045486329579926536, 0.00341147471849449, 0.0011371582394981634, 0.8666362324994367, 0.10082154189968694, 0.027886809461615536, 0.002145139189355041, 0.004290278378710082, 0.8199332188858659, 0.15254571514155646, 0.022535162464093567, 0.00346694807139901, 0.001733474035699505, 0.9334683724465191, 0.9467345855247351, 0.27078599527745006, 0.39300476219634606, 0.27110344662009656, 0.06412517121458958, 0.0009523540279394492, 0.922036516212178, 0.06146910108081187, 0.07214220195168704, 0.9378486253719316, 0.9305337209180823, 0.08459397462891657, 0.03438938218807849, 0.017194691094039247, 0.22353098422251022, 0.7221770259496484, 0.9448777599844764, 0.04323506796935144, 0.9511714953257316, 0.6022624488008121, 0.24706473730201292, 0.13196269408214883, 0.016860650862284776, 0.0017984694253103761, 0.9751323088780889, 0.03201361769920143, 0.9604085309760428, 0.2310169487059282, 0.4620338974118564, 0.09423645843841526, 0.07710255690415793, 0.8138603228772227, 0.00856695076712866, 0.06070663374917474, 0.06070663374917474, 0.9105995062376211, 0.9605151946466617, 0.04176153020202877, 0.41376527119827355, 0.30634389492138014, 0.1778563505422816, 0.10034571676164894, 0.0014472939917545518, 0.03519022019782975, 0.05278533029674462, 0.0703804403956595, 0.8379671184608208, 0.002199388762364359, 0.7194822926113681, 0.2522699510256292, 0.3852267960750088, 0.29682093575421714, 0.06473814968372935, 0.0009745527909378612, 0.11102442497668222, 0.31564791674984993, 0.29921829332280725, 0.27183558761106946, 0.001991469506308201, 0.045947302770141925, 0.9189460554028385, 0.045947302770141925, 0.08694144294602317, 0.2728406258306093, 0.36685047877224414, 0.2728406258306093, 0.000706840999561164, 0.5542561501625505, 0.5542561501625505, 0.283830400149217, 0.16683160924801307, 0.12133207945310041, 0.42682892236179965, 0.0021666442759482214, 0.0725472831281252, 0.24316774529982707, 0.2848152596881952, 0.39766658899861224, 0.0013434682060763927, 0.10337118463447668, 0.3887187255525633, 0.20028167022929858, 0.30580642121032686, 0.0010767831732757987, 0.9708766463748866, 0.9023181598146737, 0.0923842640782511, 0.2625658031697663, 0.6393963540152642, 0.004862329688329005, 0.969090596242343, 0.165077222562145, 0.3233471369773974, 0.19400828218643845, 0.31568891531214327, 0.0017018270367231442, 0.27755362934393063, 0.3091509377297856, 0.366600589340431, 0.045600660965949794, 0.0010771809676996013, 0.9788472310779249, 0.33373713359262114, 0.31500862874505836, 0.28808137928611616, 0.062214003227526196, 0.0009645581895740496, 0.9467750508351389, 0.9355977317774911, 0.9018981502097545, 0.030944442335764613, 0.061888884671529226, 0.8664443854014092, 0.030944442335764613, 0.026417468771096488, 0.2377572189398684, 0.07044658338959064, 0.6604367192774122, 0.4017412783506985, 0.2908262236681845, 0.2609978930355502, 0.045756079999574956, 0.0007239886075882114, 0.47521173693172725, 0.47521173693172725, 0.41998779132073427, 0.29814832967478744, 0.2356820298340172, 0.044133798800544195, 0.0019615021689130753, 0.7379710911420517, 0.14759421822841035, 0.06253164471505963, 0.2574832429443632, 0.22069992252373988, 0.4579523392367602, 0.8772528719099085, 0.23508646223348492, 0.21304710639909571, 0.4530312032624449, 0.09795269259728538, 0.0016325448766214231, 0.617134383823014, 0.5844855470190452, 0.9110409321371805, 0.06441703560565923, 0.018404867315902636, 0.9476512403972788, 0.04307505638169449, 0.021537528190847244, 0.07141358438930911, 0.9283765970610186, 0.7637063409951625, 0.18000704051185806, 0.04764892248843301, 0.007941487081405503, 0.0013235811802342504, 0.03167384495502464, 0.03167384495502464, 0.11085845734258626, 0.8076830463531284, 0.04487863972137796, 0.05770110821320024, 0.08975727944275592, 0.8078155149848034, 0.055917288064747016, 0.027958644032373508, 0.055917288064747016, 0.8946766090359523, 0.22578262153478645, 0.20682377545171277, 0.28201283548572087, 0.28395180838058065, 0.0015080900293354058, 0.6165508849235735, 0.4544699501075439, 0.22723497505377194, 0.22723497505377194, 0.2902822885320888, 0.20651978201007146, 0.232879374439627, 0.2691510450141807, 0.0011981632922525242, 0.5661287380449951, 0.5661287380449951, 0.32977528183343974, 0.3187321581219809, 0.2958176764207038, 0.05438738427893481, 0.00124235141753912, 0.036135944828371465, 0.018067972414185732, 0.1626117517276716, 0.781439806913533, 0.02280972336670711, 0.018247778693365687, 0.13685834020024265, 0.821150041201456, 0.6509190694828121, 0.3403895980232704, 0.3576390708960712, 0.22424314734641124, 0.07556911925227044, 0.0021356490223467736, 0.5313036275403331, 0.34211688321744976, 0.42838654855631303, 0.19352384386826088, 0.034911172094762785, 0.0010082648980436907, 0.051943612510130556, 0.23663201254615032, 0.2020029375393966, 0.5107788563496172, 0.29854987038892783, 0.3976662929532591, 0.2537273697407242, 0.04869110933510217, 0.0013340029954822512, 0.3229844733345604, 0.39114024057667657, 0.24744236678541687, 0.03726743923091082, 0.001007228087321914, 0.7570945862100416, 0.19026807902126264, 0.04640684854177138, 0.005966594812513462, 0.001325909958336325, 0.2594795052947188, 0.5875261337502182, 0.12268137232198494, 0.02924186134797997, 0.0013444533953094239, 0.04219660332738809, 0.8861286698751498, 0.04219660332738809, 0.03873872391378028, 0.9684680978445072, 0.0855145868328244, 0.8551458683282439, 0.11781325140767578, 0.17671987711151366, 0.09163252887263672, 0.6152469795734179, 0.03667107788320499, 0.014668431153281996, 0.08801058691969198, 0.8581032224669968, 0.9469289411652446, 0.9532829697312063, 0.8964091388706811, 0.5521873570846502, 0.22946962326902728, 0.17627439242029821, 0.041304532188424906, 0.0008344349937055537, 0.022023528138629393, 0.022023528138629393, 0.11011764069314696, 0.8479058333372317, 0.5712343717773701, 0.5712343717773701, 0.05389832198015256, 0.01796610732671752, 0.12576275128702263, 0.7905087223755709, 0.08970710611266715, 0.17677576792790292, 0.1371991034664321, 0.593649966922062, 0.05524754806702442, 0.8287132210053663, 0.08287132210053663, 0.02762377403351221, 0.909422588174591, 0.06624932761536755, 0.018067998440554785, 0.006022666146851595, 0.08902854209684731, 0.7344854722989903, 0.14467138090737688, 0.022257135524211828, 0.9438068944800956, 0.4869499263187896, 0.4869499263187896, 0.33748556170278277, 0.17568860960314356, 0.13728226238757266, 0.3481085939113449, 0.0008171563237355515, 0.9354782712474216, 0.04188910621639874, 0.12566731864919622, 0.7819299827061098, 0.055852141621864984, 0.3755901618671578, 0.3755901618671578, 0.8976840022033576, 0.07648428718324572, 0.022140188395150077, 0.002012744399559098, 0.002012744399559098, 0.9360446132184922, 0.8646970426033367, 0.0790078516084267, 0.04828257598292743, 0.004389325089357039, 0.004389325089357039, 0.8547454205661561, 0.11655619371356675, 0.02719644519983224, 0.1140084282094742, 0.23016795883799507, 0.6453307257140048, 0.009679960885710073, 0.0010755512095233415, 0.07810270559951064, 0.8981811143943724, 0.8384156185888378, 0.11168084494716181, 0.04370120019671549, 0.0032371259404974434, 0.0032371259404974434, 0.9023919137896085, 0.06627737219923678, 0.025491296999706457, 0.022217265654674533, 0.031104171916544344, 0.1466339533208519, 0.7998215635682832, 0.9183671125763704, 0.06974940095516736, 0.011624900159194563, 0.8288737581959509, 0.13570057103208044, 0.031785719340847673, 0.0024450553339113597, 0.0012225276669556799, 0.018080634991907367, 0.12656444494335156, 0.8136285746358315, 0.036161269983814734, 0.9273199148523796, 0.9104048004120369, 0.9522679928586224, 0.02885660584420068, 0.12952291757711423, 0.25303422294600797, 0.34484793667155733, 0.27106905957066946, 0.001093020401494635, 0.0384160340644805, 0.921984817547532, 0.0384160340644805, 0.08473653993828542, 0.6165313767923526, 0.27758521703921085, 0.017531697918265948, 0.002921949653044325, 0.02488197748524753, 0.12440988742623765, 0.8335462457557923, 0.012440988742623765, 0.8910837028534558, 0.06536907472670139, 0.03784525378914291, 0.0034404776171948104, 0.0034404776171948104, 0.47521173693172725, 0.47521173693172725, 0.9417817947726389, 0.41726323058281034, 0.22015602832654946, 0.2847324806786511, 0.07590216861077788, 0.0019869677646800494, 0.8933864130684535, 0.08063820355487229, 0.021220579882861128, 0.0021220579882861128, 0.0021220579882861128, 0.7662338894311309, 0.15324677788622618, 0.03464133021582398, 0.0461884402877653, 0.7621092647481276, 0.16165954100717855, 0.918766687619175, 0.043338051302791274, 0.03467044104223302, 0.002889203420186085, 0.002889203420186085, 0.5675824927425193, 0.11155338097930692, 0.2690405070677402, 0.5971386864186429, 0.01968589076105416, 0.12345865130007048, 0.3442317689190201, 0.49383460520028194, 0.036311368029432495, 0.0014524547211773, 0.01239893486428021, 0.02479786972856042, 0.04959573945712084, 0.9051222450924553, 0.032460006635685434, 0.16230003317842717, 0.7952701625742932, 0.030441304505845347, 0.12176521802338139, 0.8523565261636697, 0.030441304505845347, 0.9312238931493132, 0.03285112634773349, 0.9526826640842713, 0.8198358198082145, 0.13596287110680785, 0.04261522825735768, 0.0020292965836836993, 0.9293097041121562, 0.9755244350029573, 0.09638032868324414, 0.032126776227748045, 0.8674229581491972, 0.9363420396854946, 0.7508539719273118, 0.18298122004951298, 0.06151954812009488, 0.0031548486215433273, 0.0015774243107716636, 0.8153015626324364, 0.1567887620446993, 0.023518314306704896, 0.0019598595255587415, 0.0019598595255587415, 0.9515490276371087, 0.019030980552742174, 0.019030980552742174, 0.8804559014183598, 0.10426451464164788, 0.01737741910694131, 0.31964730619012643, 0.3353400404973188, 0.2612998242694246, 0.08162328247029588, 0.0021064072895560226, 0.3771171615532608, 0.3686643837084994, 0.21953008709845145, 0.0337230616098293, 0.0009685474613789094, 0.027278253267643292, 0.9547388643675152, 0.3723734505286326, 0.25102921195318945, 0.330400720555752, 0.045739513431985214, 0.0008071678840938567, 0.26825685391839854, 0.42191995702920837, 0.23470659227511212, 0.07421724545333062, 0.0010166745952511044, 0.36802753649865894, 0.27583477988081306, 0.2881767134280408, 0.0667653995506658, 0.0013382819509042143, 0.047574483329890095, 0.09514896665978019, 0.06343264443985346, 0.7929080554981682, 0.9544643436098506, 0.051504333604956584, 0.9270780048892184, 0.03567821894970766, 0.08324917754931786, 0.05946369824951276, 0.8205990358432761, 0.2232745404371987, 0.4117059420565805, 0.27445841523056375, 0.08983740944404515, 0.0007694068508666184, 0.939832041513947, 0.04086226267451943, 0.9414503992648678, 0.22940090963643459, 0.3939711274190942, 0.30387308899666843, 0.07214492375522653, 0.0009973952592888461, 0.9305730770271742, 0.06646950550194101, 0.2510999484910956, 0.5562829628110426, 0.1559716987742767, 0.035250569692019194, 0.00144865354898709, 0.6529610130247997, 0.9153650105787123, 0.47455054022547827, 0.3013803535008243, 0.1042479583420884, 0.11882290986384958, 0.0009881323065600797, 0.46950513093946716, 0.2991963961938968, 0.158076340950706, 0.07210150814046043, 0.0010939539166138824, 0.3133749266658384, 0.5255612443918014, 0.13663903996302892, 0.02237163122820373, 0.0020650736518341905, 0.43644403897000383, 0.43132145635298497, 0.10108563030917146, 0.029881731932609807, 0.0013660220312050198, 0.14143007767416982, 0.8014371068202956, 0.031428906149815514, 0.031428906149815514, 0.4402893187355432, 0.32513506420377664, 0.1505114763457456, 0.08293268847499058, 0.0010812606059320807, 0.889272241418805, 0.03365203893951126, 0.03365203893951126, 0.9086050513668041, 0.03365203893951126, 0.26157840434640733, 0.23085447848770677, 0.4748243087253726, 0.031816871837863844, 0.0009715075370340105, 0.22737292674111143, 0.372735389447738, 0.35971785547401025, 0.03948651972030752, 0.0008678355982485169, 0.9814315653951704, 0.9612945630679249, 0.0369728678103048, 0.9890857241492473], \"Term\": [\"\\n\\n\", \"\\n\\n\", \"\\n\\n\", \"\\n\\n\", \"\\n\\n\", \" \", \" \", \" \", \" \", \" \", \"!\", \"!\", \"!\", \"!\", \"!\", \"\\\"\", \"\\\"\", \"\\\"\", \"\\\"\", \"\\\"\", \"&\", \"&\", \"&\", \"&\", \"&\", \"'s\", \"'s\", \"'s\", \"'s\", \"'s\", \",\", \",\", \",\", \",\", \",\", \"-\", \"-\", \"-\", \"-\", \"-\", \".\", \".\", \".\", \".\", \".\", \"..\", \"..\", \"..\", \"..\", \"..\", \"...\", \"...\", \"...\", \"...\", \"...\", \"....\", \"....\", \"....\", \"....\", \"....\", \"?\", \"?\", \"?\", \"?\", \"?\", \"ANYONE\", \"Acura\", \"Adam\", \"Aladdin\", \"Aladdin\", \"Aladdin\", \"Animal\", \"Asia\", \"Asia\", \"Ate\", \"Bars\", \"Beers\", \"Ben\", \"Ben\", \"Ben\", \"Ben\", \"Bonus\", \"Bonus\", \"Bonus\", \"CHECK\", \"Curry\", \"DO\", \"DO\", \"DO\", \"DO\", \"Debbie\", \"Depot\", \"Doctor\", \"Doctor\", \"Dr.\", \"Dr.\", \"Dr.\", \"Dr.\", \"Easter\", \"Filled\", \"Free\", \"Free\", \"Free\", \"Girl\", \"Girl\", \"HERE\", \"HERE\", \"HERE\", \"He\", \"He\", \"He\", \"He\", \"He\", \"Hidden\", \"Hip\", \"Howard\", \"I\", \"I\", \"I\", \"I\", \"I\", \"ID\", \"ID\", \"IPA\", \"IPA\", \"It\", \"It\", \"It\", \"It\", \"It\", \"Jamie\", \"Jenn\", \"Johnny\", \"Johnny\", \"Josh\", \"Josh\", \"LOVE\", \"LOVE\", \"LOVE\", \"LOVE\", \"Ladies\", \"Lewis\", \"Macy\", \"Margarita\", \"Massage\", \"Massage\", \"Meat\", \"Meat\", \"Mexican\", \"Mexican\", \"Mexican\", \"Mexican\", \"Motel\", \"NOT\", \"NOT\", \"NOT\", \"NOT\", \"Nachos\", \"Nachos\", \"Noodles\", \"Noodles\", \"OVER\", \"PLACE\", \"PLACE\", \"Pad\", \"Pad\", \"Pest\", \"RECOMMEND\", \"She\", \"She\", \"She\", \"She\", \"She\", \"Step\", \"Suzi\", \"Swedish\", \"Swedish\", \"TIME\", \"TO\", \"TO\", \"TO\", \"TO\", \"Thai\", \"Thai\", \"Thai\", \"Thai\", \"The\", \"The\", \"The\", \"The\", \"The\", \"Tikka\", \"Tony\", \"Tony\", \"Tony\", \"Tony\", \"Typical\", \"UP\", \"Vinyl\", \"Waitress\", \"Waitress\", \"We\", \"We\", \"We\", \"We\", \"We\", \"X\", \"X\", \"X\", \"YOUR\", \"YOUR\", \"YOUR\", \"Yuk\", \"ZERO\", \"ZERO\", \"ZERO\", \"_\", \"_\", \"_\", \"_\", \"_\", \"a\", \"a\", \"a\", \"a\", \"a\", \"about\", \"about\", \"about\", \"about\", \"about\", \"accessories\", \"accessories\", \"accommodations\", \"acrylics\", \"airline\", \"airline\", \"airlines\", \"airport\", \"airport\", \"airport\", \"airport\", \"an\", \"an\", \"an\", \"an\", \"an\", \"and\", \"and\", \"and\", \"and\", \"and\", \"appointment\", \"appointment\", \"appointment\", \"appointment\", \"appointments\", \"appointments\", \"appointments\", \"appointments\", \"are\", \"are\", \"are\", \"are\", \"are\", \"as\", \"as\", \"as\", \"as\", \"as\", \"at\", \"at\", \"at\", \"at\", \"at\", \"attorney\", \"attorney\", \"auch\", \"auch\", \"authentic\", \"authentic\", \"authentic\", \"authentic\", \"authority\", \"avec\", \"avec\", \"badass\", \"barber\", \"barber\", \"barber\", \"barber\", \"bath\", \"bath\", \"bath\", \"be\", \"be\", \"be\", \"be\", \"be\", \"beef\", \"beef\", \"beef\", \"beef\", \"beef\", \"bento\", \"bikes\", \"bikes\", \"boots\", \"boots\", \"border\", \"brakes\", \"brandade\", \"bread\", \"bread\", \"bread\", \"bread\", \"bread\", \"broth\", \"broth\", \"broth\", \"bumper\", \"bumper\", \"bumper\", \"but\", \"but\", \"but\", \"but\", \"but\", \"canals\", \"car\", \"car\", \"car\", \"car\", \"car\", \"cauliflower\", \"cauliflower\", \"cavities\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chipotle\", \"class\", \"class\", \"class\", \"class\", \"classes\", \"classes\", \"classes\", \"classes\", \"clowns\", \"colleague\", \"colleague\", \"colorist\", \"colorist\", \"consultation\", \"consultation\", \"consultation\", \"consultation\", \"couples\", \"couples\", \"cream\", \"cream\", \"cream\", \"cream\", \"cream\", \"crispy\", \"crispy\", \"crispy\", \"crispy\", \"cuisine\", \"cuisine\", \"cuisine\", \"cuisine\", \"curry\", \"curry\", \"curry\", \"curry\", \"d'oignons\", \"dans\", \"de\", \"de\", \"de\", \"de\", \"dealership\", \"dealership\", \"dealership\", \"dealership\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"dental\", \"dental\", \"dental\", \"dental\", \"dentist\", \"dentist\", \"dentist\", \"dentist\", \"desk\", \"desk\", \"desk\", \"desk\", \"did\", \"did\", \"did\", \"did\", \"did\", \"dish\", \"dish\", \"dish\", \"dish\", \"dish\", \"do\", \"do\", \"do\", \"do\", \"do\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"emailed\", \"emailed\", \"en\", \"en\", \"en\", \"enchilada\", \"enchiladas\", \"enchiladas\", \"enchiladas\", \"est\", \"est\", \"establishments\", \"et\", \"et\", \"et\", \"facials\", \"facials\", \"flavor\", \"flavor\", \"flavor\", \"flavor\", \"flavor\", \"floral\", \"food\", \"food\", \"food\", \"food\", \"food\", \"for\", \"for\", \"for\", \"for\", \"for\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"fried\", \"fried\", \"fried\", \"fried\", \"fried\", \"fries\", \"fries\", \"fries\", \"fries\", \"fries\", \"frills\", \"frittata\", \"from\", \"from\", \"from\", \"from\", \"from\", \"frustration\", \"frustration\", \"fryer\", \"fryer\", \"gates\", \"gates\", \"gel\", \"gel\", \"gel\", \"gel\", \"ghetto\", \"goals\", \"goals\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gooey\", \"greatest\", \"greatest\", \"gumbo\", \"gumbo\", \"gym\", \"gym\", \"gym\", \"gym\", \"gyms\", \"gyms\", \"gyms\", \"gyros\", \"gyros\", \"had\", \"had\", \"had\", \"had\", \"had\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"halo\", \"have\", \"have\", \"have\", \"have\", \"have\", \"he\", \"he\", \"he\", \"he\", \"he\", \"heater\", \"heater\", \"heater\", \"her\", \"her\", \"her\", \"her\", \"her\", \"hier\", \"hier\", \"highly\", \"highly\", \"highly\", \"highly\", \"highly\", \"him\", \"him\", \"him\", \"him\", \"him\", \"his\", \"his\", \"his\", \"his\", \"his\", \"horribly\", \"horrific\", \"hotel\", \"hotel\", \"hotel\", \"hotel\", \"humor\", \"i\", \"i\", \"i\", \"i\", \"i\", \"if\", \"if\", \"if\", \"if\", \"if\", \"implants\", \"in\", \"in\", \"in\", \"in\", \"in\", \"increase\", \"increased\", \"inspected\", \"instructors\", \"instructors\", \"instructors\", \"instructors\", \"insurance\", \"insurance\", \"insurance\", \"insurance\", \"is\", \"is\", \"is\", \"is\", \"is\", \"ist\", \"ist\", \"it\", \"it\", \"it\", \"it\", \"it\", \"j'ai\", \"j'ai\", \"job\", \"job\", \"job\", \"job\", \"knocking\", \"know\", \"know\", \"know\", \"know\", \"know\", \"l'ensemble\", \"l'entr\\u00e9e\", \"la\", \"la\", \"la\", \"le\", \"le\", \"le\", \"lenses\", \"lenses\", \"lunch\", \"lunch\", \"lunch\", \"lunch\", \"lunch\", \"manicure\", \"manicure\", \"manicure\", \"manicure\", \"massage\", \"massage\", \"massage\", \"massage\", \"massages\", \"massages\", \"massages\", \"massages\", \"me\", \"me\", \"me\", \"me\", \"me\", \"memorabilia\", \"monster\", \"monster\", \"monster\", \"my\", \"my\", \"my\", \"my\", \"my\", \"n'ai\", \"n'ai\", \"n't\", \"n't\", \"n't\", \"n't\", \"n't\", \"nail\", \"nail\", \"nail\", \"nail\", \"nails\", \"nails\", \"nails\", \"nails\", \"nite\", \"not\", \"not\", \"not\", \"not\", \"not\", \"oder\", \"of\", \"of\", \"of\", \"of\", \"of\", \"office\", \"office\", \"office\", \"office\", \"on\", \"on\", \"on\", \"on\", \"on\", \"one\", \"one\", \"one\", \"one\", \"one\", \"ordered\", \"ordered\", \"ordered\", \"ordered\", \"ordered\", \"our\", \"our\", \"our\", \"our\", \"our\", \"p.m.\", \"p.m.\", \"p.m.\", \"painting\", \"painting\", \"passengers\", \"passengers\", \"patient\", \"patient\", \"patient\", \"patient\", \"pedicure\", \"pedicure\", \"pedicure\", \"pedicure\", \"permanently\", \"pharmacy\", \"pinball\", \"place\", \"place\", \"place\", \"place\", \"place\", \"polish\", \"polish\", \"polish\", \"polish\", \"poss\\u00e8de\", \"poss\\u00e8de\", \"procedure\", \"procedure\", \"procedure\", \"procedure\", \"professional\", \"professional\", \"professional\", \"professional\", \"promised\", \"promised\", \"promised\", \"promised\", \"ramen\", \"ramen\", \"ramen\", \"ramen\", \"range\", \"range\", \"range\", \"range\", \"readings\", \"receptive\", \"receptive\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"removal\", \"rent\", \"rent\", \"rent\", \"rent\", \"reptiles\", \"reptiles\", \"rice\", \"rice\", \"rice\", \"rice\", \"rice\", \"ricotta\", \"roll\", \"roll\", \"roll\", \"roll\", \"roll\", \"rolls\", \"rolls\", \"rolls\", \"room\", \"room\", \"room\", \"room\", \"room\", \"routine\", \"routine\", \"salad\", \"salad\", \"salad\", \"salad\", \"salad\", \"salmon\", \"salmon\", \"salmon\", \"salon\", \"salon\", \"salon\", \"salon\", \"sashimi\", \"sashimi\", \"sashimi\", \"sauce\", \"sauce\", \"sauce\", \"sauce\", \"sauce\", \"security\", \"security\", \"security\", \"security\", \"sensor\", \"servicing\", \"shawarma\", \"shawarma\", \"she\", \"she\", \"she\", \"she\", \"she\", \"shout\", \"shout\", \"shout\", \"show\", \"show\", \"show\", \"show\", \"show\", \"shower\", \"shower\", \"shower\", \"shower\", \"shrimp\", \"shrimp\", \"shrimp\", \"shrimp\", \"shrimp\", \"sich\", \"sich\", \"smokey\", \"so\", \"so\", \"so\", \"so\", \"so\", \"soup\", \"soup\", \"soup\", \"soup\", \"soup\", \"souvlaki\", \"souvlaki\", \"spa\", \"spa\", \"spa\", \"spa\", \"spicy\", \"spicy\", \"spicy\", \"spicy\", \"spicy\", \"spiritual\", \"stay\", \"stay\", \"stay\", \"stay\", \"store\", \"store\", \"store\", \"store\", \"store\", \"stylist\", \"stylist\", \"stylist\", \"stylist\", \"suite\", \"suite\", \"suite\", \"supplies\", \"supplies\", \"supplies\", \"supplies\", \"surgeon\", \"surgery\", \"surgery\", \"sushi\", \"sushi\", \"sushi\", \"sushi\", \"sweetest\", \"tamale\", \"tan\", \"tan\", \"tan\", \"tartar\", \"taste\", \"taste\", \"taste\", \"taste\", \"taste\", \"tasty\", \"tasty\", \"tasty\", \"tasty\", \"tasty\", \"tempura\", \"tempura\", \"tempura\", \"tender\", \"tender\", \"tender\", \"that\", \"that\", \"that\", \"that\", \"that\", \"the\", \"the\", \"the\", \"the\", \"the\", \"therapist\", \"therapist\", \"there\", \"there\", \"there\", \"there\", \"there\", \"they\", \"they\", \"they\", \"they\", \"they\", \"this\", \"this\", \"this\", \"this\", \"this\", \"thorough\", \"thorough\", \"thorough\", \"thorough\", \"tiles\", \"tint\", \"tint\", \"tire\", \"tire\", \"tire\", \"tire\", \"to\", \"to\", \"to\", \"to\", \"to\", \"tr\\u00e8s\", \"tr\\u00e8s\", \"und\", \"up\", \"up\", \"up\", \"up\", \"up\", \"urban\", \"urban\", \"us\", \"us\", \"us\", \"us\", \"us\", \"v\", \"vary\", \"very\", \"very\", \"very\", \"very\", \"very\", \"was\", \"was\", \"was\", \"was\", \"was\", \"we\", \"we\", \"we\", \"we\", \"we\", \"were\", \"were\", \"were\", \"were\", \"were\", \"windows\", \"windows\", \"windows\", \"windows\", \"with\", \"with\", \"with\", \"with\", \"with\", \"worthwhile\", \"yoga\", \"yoga\", \"yoga\", \"yoga\", \"you\", \"you\", \"you\", \"you\", \"you\", \"your\", \"your\", \"your\", \"your\", \"your\", \"yuk\", \"\\u00e0\", \"\\u00e0\", \"\\u3002\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 1, 4, 5, 2]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el64571370582298795207938405914\", ldavis_el64571370582298795207938405914_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el64571370582298795207938405914\", ldavis_el64571370582298795207938405914_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el64571370582298795207938405914\", ldavis_el64571370582298795207938405914_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Cell for pyLDAvis visualization\n",
        "# YOUR CODE HERE\n",
        "import pyLDAvis #Fixed: Added pyLDAvis to imports\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "# Visualize the topics\n",
        "vis_data = gensimvis.prepare(lda, corpus, id2word)\n",
        "pyLDAvis.display(vis_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2cb1397c6a59aa5751d77bad34994f29",
          "grade": false,
          "grade_id": "cell-9b043e992fbd218c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "CRivWgOpDOVg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "f5178323-b82d-42d9-e6fd-f42455ddf3fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Cell for matplotlib visualzation\n",
        "# YOUR CODE HERE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the top 3 words for each topic\n",
        "top_words = [[word for word, prob in lda.show_topic(i, topn=3)] for i in range(num_topics)]\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, num_topics, figsize=(15, 5))\n",
        "\n",
        "# Plot the top words for each topic\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.bar(top_words[i], [1, 1, 1])  # Bar chart for top words\n",
        "    ax.set_title(f'Topic {i + 1}')  # Set subplot title\n",
        "    ax.tick_params(axis='x', rotation=45)  # Rotate x-axis labels\n",
        "\n",
        "# Adjust layout and assign to visual_plot\n",
        "plt.tight_layout()  # Improve spacing\n",
        "visual_plot = plt  # Assign the plot to visual_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "97e1c557c7e019c69cc2714b055fb767",
          "grade": true,
          "grade_id": "cell-f5fa579a25122b47",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "w5hefHJRDOVg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc42e742-a8da-4566-a39f-74bcd9a03cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Visible testing\n",
        "assert visual_plot is not None, \"Variable 'visual_plot' is not created.\""
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "u4-s1-nlp"
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "nteract": {
      "version": "0.15.0"
    },
    "toc-autonumbering": false,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}